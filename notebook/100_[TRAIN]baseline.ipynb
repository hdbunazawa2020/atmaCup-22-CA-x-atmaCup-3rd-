{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude Codeに雑にベースライン作ってとお願いしてみたら、ほぼ初手で0.8448の精度が出ました（今年のvibe codingの進歩は凄かったですね）  \n",
    "\n",
    "改善出来るところはいくらでもあると思うので、ノートブックを共有します！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ベースラインモデルの設定\"\"\"\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # パス設定\n",
    "    data_dir: Path = Path(\"../data/raw\")\n",
    "    image_dir: Path = Path(\"../data/raw/images\")\n",
    "    crop_dir: Path = Path(\"../data/processed/crops\")  # 事前クロップ済み画像\n",
    "    output_dir: Path = Path(\"../output\")\n",
    "    use_crops: bool = True  # 事前クロップ済み画像を使用（高速化）\n",
    "\n",
    "    # モデル設定\n",
    "    model_name: str = \"resnet18\"\n",
    "    num_classes: int = 11  # label_id 0-10\n",
    "    pretrained: bool = True\n",
    "    img_size: int = 224\n",
    "\n",
    "    # 学習設定\n",
    "    batch_size: int = 128\n",
    "    num_workers: int = 8\n",
    "    epochs: int = 20\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "\n",
    "    # 検証設定\n",
    "    val_ratio: float = 0.2\n",
    "    seed: int = 42\n",
    "\n",
    "    # デバイス\n",
    "    device: str = \"cuda\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"選手再識別用モデル定義\"\"\"\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PlayerClassifier(nn.Module):\n",
    "    \"\"\"選手再識別用CNN分類器\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"resnet18\",\n",
    "        num_classes: int = 11,\n",
    "        pretrained: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=num_classes,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "def create_model(\n",
    "    model_name: str = \"resnet18\",\n",
    "    num_classes: int = 11,\n",
    "    pretrained: bool = True,\n",
    ") -> PlayerClassifier:\n",
    "    \"\"\"モデルインスタンスを作成\"\"\"\n",
    "    return PlayerClassifier(\n",
    "        model_name=model_name,\n",
    "        num_classes=num_classes,\n",
    "        pretrained=pretrained,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. データセットとデータローダー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"選手再識別用データセット\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "def get_image_path(row: pd.Series, image_dir: Path) -> Path:\n",
    "    \"\"\"行データから画像パスを生成\"\"\"\n",
    "    fname = f\"{row['quarter']}__{row['angle']}__{row['session']:02d}__{row['frame']:02d}.jpg\"\n",
    "    return image_dir / fname\n",
    "\n",
    "\n",
    "def get_train_transform(img_size: int) -> A.Compose:\n",
    "    \"\"\"学習用augmentationを取得\"\"\"\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(img_size, img_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_val_transform(img_size: int) -> A.Compose:\n",
    "    \"\"\"検証/テスト用変換を取得\"\"\"\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(img_size, img_size),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "class PlayerDataset(Dataset):\n",
    "    \"\"\"選手バウンディングボックス分類用データセット\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        image_dir: Path,\n",
    "        transform: A.Compose,\n",
    "        is_test: bool = False,\n",
    "        cache_images: bool = False,\n",
    "        crop_dir: Path = None,\n",
    "    ):\n",
    "        # クロップファイル検索用に元のインデックスを保持\n",
    "        self.original_indices = df.index.tolist()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.cache_images = cache_images\n",
    "        self.image_cache = {}\n",
    "        self.crop_dir = Path(crop_dir) if crop_dir else None\n",
    "        self.use_crops = crop_dir is not None\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def _load_image(self, img_path: Path) -> np.ndarray:\n",
    "        \"\"\"キャッシュ付き画像読み込み\"\"\"\n",
    "        if self.cache_images and str(img_path) in self.image_cache:\n",
    "            return self.image_cache[str(img_path)]\n",
    "\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"画像を読み込めませんでした: {img_path}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.cache_images:\n",
    "            self.image_cache[str(img_path)] = img\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        if self.use_crops:\n",
    "            # 事前クロップ済み画像を直接読み込み（元のインデックスを使用）\n",
    "            original_idx = self.original_indices[idx]\n",
    "            crop_path = self.crop_dir / f\"{original_idx}.jpg\"\n",
    "            crop = self._load_image(crop_path)\n",
    "        else:\n",
    "            # 全体画像を読み込んでクロップ\n",
    "            img_path = get_image_path(row, self.image_dir)\n",
    "            img = self._load_image(img_path)\n",
    "\n",
    "            # パディング付きでバウンディングボックスをクロップ\n",
    "            x, y, w, h = int(row[\"x\"]), int(row[\"y\"]), int(row[\"w\"]), int(row[\"h\"])\n",
    "            img_h, img_w = img.shape[:2]\n",
    "\n",
    "            # パディング追加（bboxサイズの10%）\n",
    "            pad_w = int(w * 0.1)\n",
    "            pad_h = int(h * 0.1)\n",
    "\n",
    "            x1 = max(0, x - pad_w)\n",
    "            y1 = max(0, y - pad_h)\n",
    "            x2 = min(img_w, x + w + pad_w)\n",
    "            y2 = min(img_h, y + h + pad_h)\n",
    "\n",
    "            crop = img[y1:y2, x1:x2]\n",
    "\n",
    "        # 変換を適用\n",
    "        transformed = self.transform(image=crop)\n",
    "        image = transformed[\"image\"]\n",
    "\n",
    "        result = {\n",
    "            \"image\": image,\n",
    "            \"angle\": row[\"angle\"],\n",
    "        }\n",
    "\n",
    "        if not self.is_test:\n",
    "            result[\"label\"] = torch.tensor(row[\"label_id\"], dtype=torch.long)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def create_dataloader(\n",
    "    df: pd.DataFrame,\n",
    "    image_dir: Path,\n",
    "    img_size: int,\n",
    "    batch_size: int,\n",
    "    num_workers: int,\n",
    "    is_train: bool = True,\n",
    "    is_test: bool = False,\n",
    "    crop_dir: Path = None,\n",
    ") -> torch.utils.data.DataLoader:\n",
    "    \"\"\"データローダーを作成\"\"\"\n",
    "    transform = get_train_transform(img_size) if is_train else get_val_transform(img_size)\n",
    "\n",
    "    dataset = PlayerDataset(\n",
    "        df=df,\n",
    "        image_dir=image_dir,\n",
    "        transform=transform,\n",
    "        is_test=is_test,\n",
    "        crop_dir=crop_dir,\n",
    "    )\n",
    "\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=is_train,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=is_train,\n",
    "        persistent_workers=num_workers > 0,\n",
    "        prefetch_factor=2 if num_workers > 0 else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 画像の事前クロップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"学習高速化のための画像事前クロップ処理\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def get_image_path(row: pd.Series, image_dir: Path) -> Path:\n",
    "    \"\"\"行データから画像パスを生成\"\"\"\n",
    "    fname = f\"{row['quarter']}__{row['angle']}__{row['session']:02d}__{row['frame']:02d}.jpg\"\n",
    "    return image_dir / fname\n",
    "\n",
    "\n",
    "def process_single_crop(args: tuple) -> tuple[int, bool]:\n",
    "    \"\"\"単一クロップを処理。(idx, success)を返す\"\"\"\n",
    "    idx, row, image_dir, output_dir, padding_ratio = args\n",
    "\n",
    "    try:\n",
    "        img_path = get_image_path(row, image_dir)\n",
    "        img = cv2.imread(str(img_path))\n",
    "\n",
    "        if img is None:\n",
    "            return idx, False\n",
    "\n",
    "        # パディング付きでbboxを取得\n",
    "        x, y, w, h = int(row[\"x\"]), int(row[\"y\"]), int(row[\"w\"]), int(row[\"h\"])\n",
    "        img_h, img_w = img.shape[:2]\n",
    "\n",
    "        pad_w = int(w * padding_ratio)\n",
    "        pad_h = int(h * padding_ratio)\n",
    "\n",
    "        x1 = max(0, x - pad_w)\n",
    "        y1 = max(0, y - pad_h)\n",
    "        x2 = min(img_w, x + w + pad_w)\n",
    "        y2 = min(img_h, y + h + pad_h)\n",
    "\n",
    "        crop = img[y1:y2, x1:x2]\n",
    "\n",
    "        # クロップを保存\n",
    "        output_path = output_dir / f\"{idx}.jpg\"\n",
    "        cv2.imwrite(str(output_path), crop, [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
    "\n",
    "        return idx, True\n",
    "    except Exception as e:\n",
    "        print(f\"idx {idx} の処理中にエラー: {e}\")\n",
    "        return idx, False\n",
    "\n",
    "\n",
    "def preprocess_crops(\n",
    "    csv_path: Path,\n",
    "    image_dir: Path,\n",
    "    output_dir: Path,\n",
    "    padding_ratio: float = 0.1,\n",
    "    num_workers: int = None,\n",
    "):\n",
    "    \"\"\"全バウンディングボックスを事前クロップして保存\"\"\"\n",
    "    if num_workers is None:\n",
    "        num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"{len(df)} サンプルを {num_workers} ワーカーで処理中...\")\n",
    "\n",
    "    # 並列処理用の引数を準備\n",
    "    args_list = [(idx, row, image_dir, output_dir, padding_ratio) for idx, row in df.iterrows()]\n",
    "\n",
    "    # 並列処理\n",
    "    success_count = 0\n",
    "    failed_indices = []\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = {executor.submit(process_single_crop, args): args[0] for args in args_list}\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"クロップ中\"):\n",
    "            idx, success = future.result()\n",
    "            if success:\n",
    "                success_count += 1\n",
    "            else:\n",
    "                failed_indices.append(idx)\n",
    "\n",
    "    print(f\"完了: {success_count}/{len(df)} クロップを保存\")\n",
    "    if failed_indices:\n",
    "        print(f\"失敗したインデックス: {failed_indices[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24920 サンプルを 32 ワーカーで処理中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "クロップ中: 100%|██████████| 24920/24920 [01:12<00:00, 344.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完了: 24920/24920 クロップを保存\n",
      "7500 サンプルを 32 ワーカーで処理中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "クロップ中: 100%|██████████| 7500/7500 [00:21<00:00, 354.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完了: 7500/7500 クロップを保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 前処理を実行（実行する場合はコメントを解除）\n",
    "cfg = Config()\n",
    "\n",
    "# 学習データを処理\n",
    "preprocess_crops(\n",
    "    csv_path=cfg.data_dir / \"train_meta.csv\",\n",
    "    image_dir=cfg.image_dir,\n",
    "    output_dir=cfg.crop_dir / \"train\",\n",
    ")\n",
    "\n",
    "# テストデータが存在する場合は処理\n",
    "test_csv = cfg.data_dir / \"test_meta.csv\"\n",
    "if test_csv.exists():\n",
    "    preprocess_crops(\n",
    "        csv_path=test_csv,\n",
    "        image_dir=cfg.image_dir,\n",
    "        output_dir=cfg.crop_dir / \"test\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"選手再識別の学習スクリプト\"\"\"\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "\n",
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: torch.utils.data.DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: str,\n",
    ") -> float:\n",
    "    \"\"\"1エポック分の学習\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"学習\")\n",
    "    for batch in pbar:\n",
    "        images = batch[\"image\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        num_samples += images.size(0)\n",
    "        pbar.set_postfix({\"loss\": total_loss / num_samples})\n",
    "\n",
    "    return total_loss / num_samples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(\n",
    "    model: nn.Module,\n",
    "    loader: torch.utils.data.DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: str,\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"モデルの検証\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"検証\"):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        num_samples += images.size(0)\n",
    "\n",
    "    return total_loss / num_samples, correct / num_samples\n",
    "\n",
    "\n",
    "def train_main():\n",
    "    cfg = Config()\n",
    "    print(f\"設定: {cfg}\")\n",
    "\n",
    "    # シード設定\n",
    "    torch.manual_seed(cfg.seed)\n",
    "\n",
    "    # データ読み込み\n",
    "    train_df = pd.read_csv(cfg.data_dir / \"train_meta.csv\")\n",
    "    print(f\"学習サンプル数: {len(train_df)}\")\n",
    "\n",
    "    # quarterでグループ分割（データリーケージ防止のためゲーム単位で分割）\n",
    "    train_df[\"group\"] = train_df[\"quarter\"]\n",
    "    sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=cfg.seed)\n",
    "\n",
    "    # 最初のfoldを検証用に使用\n",
    "    train_idx, val_idx = next(sgkf.split(train_df, train_df[\"label_id\"], train_df[\"group\"]))\n",
    "    train_data = train_df.iloc[train_idx]\n",
    "    val_data = train_df.iloc[val_idx]\n",
    "\n",
    "    print(f\"学習: {len(train_data)}, 検証: {len(val_data)}\")\n",
    "    print(f\"検証quarters: {val_data['quarter'].unique()}\")\n",
    "\n",
    "    # データローダー作成\n",
    "    crop_dir = cfg.crop_dir / \"train\" if cfg.use_crops else None\n",
    "    train_loader = create_dataloader(\n",
    "        train_data, cfg.image_dir, cfg.img_size, cfg.batch_size, cfg.num_workers, is_train=True, crop_dir=crop_dir\n",
    "    )\n",
    "    val_loader = create_dataloader(\n",
    "        val_data, cfg.image_dir, cfg.img_size, cfg.batch_size, cfg.num_workers, is_train=False, crop_dir=crop_dir\n",
    "    )\n",
    "\n",
    "    # モデル作成\n",
    "    model = create_model(cfg.model_name, cfg.num_classes, cfg.pretrained)\n",
    "    model = model.to(cfg.device)\n",
    "    print(f\"モデル: {cfg.model_name}\")\n",
    "\n",
    "    # 損失関数とオプティマイザ\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.epochs)\n",
    "\n",
    "    # 学習ループ\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(cfg.epochs):\n",
    "        print(f\"\\nエポック {epoch + 1}/{cfg.epochs}\")\n",
    "\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, cfg.device)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, cfg.device)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"学習Loss: {train_loss:.4f}, 検証Loss: {val_loss:.4f}, 検証Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), cfg.output_dir / \"best_model.pth\")\n",
    "            print(f\"ベストモデルを保存! Acc: {best_acc:.4f}\")\n",
    "\n",
    "    print(f\"\\n学習完了。ベスト精度: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "設定: Config(data_dir=PosixPath('/kaggle/input/atmacup22'), image_dir=PosixPath('/kaggle/input/atmacup22/images'), crop_dir=PosixPath('/kaggle/dataset/crops'), output_dir=PosixPath('/kaggle/output'), use_crops=True, model_name='resnet18', num_classes=11, pretrained=True, img_size=224, batch_size=128, num_workers=8, epochs=20, lr=0.001, weight_decay=0.0001, val_ratio=0.2, seed=42, device='cuda')\n",
      "学習サンプル数: 24920\n",
      "学習: 19660, 検証: 5260\n",
      "検証quarters: ['Q1-000' 'Q1-003' 'Q2-000' 'Q2-004' 'Q2-012' 'Q2-016']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/.venv/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデル: resnet18\n",
      "\n",
      "エポック 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:15<00:00,  9.82it/s, loss=0.705]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.7054, 検証Loss: 0.2291, 検証Acc: 0.9287\n",
      "ベストモデルを保存! Acc: 0.9287\n",
      "\n",
      "エポック 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:15<00:00, 10.16it/s, loss=0.133]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 15.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.1330, 検証Loss: 0.1583, 検証Acc: 0.9487\n",
      "ベストモデルを保存! Acc: 0.9487\n",
      "\n",
      "エポック 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:14<00:00, 10.33it/s, loss=0.0872]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 15.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0872, 検証Loss: 0.1310, 検証Acc: 0.9574\n",
      "ベストモデルを保存! Acc: 0.9574\n",
      "\n",
      "エポック 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:14<00:00, 10.22it/s, loss=0.0644]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0644, 検証Loss: 0.1282, 検証Acc: 0.9639\n",
      "ベストモデルを保存! Acc: 0.9639\n",
      "\n",
      "エポック 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:15<00:00, 10.20it/s, loss=0.0511]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0511, 検証Loss: 0.0993, 検証Acc: 0.9711\n",
      "ベストモデルを保存! Acc: 0.9711\n",
      "\n",
      "エポック 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:14<00:00, 10.23it/s, loss=0.0386]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0386, 検証Loss: 0.1120, 検証Acc: 0.9684\n",
      "\n",
      "エポック 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:14<00:00, 10.22it/s, loss=0.0334]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 14.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0334, 検証Loss: 0.0975, 検証Acc: 0.9713\n",
      "ベストモデルを保存! Acc: 0.9713\n",
      "\n",
      "エポック 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:14<00:00, 10.25it/s, loss=0.0271]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0271, 検証Loss: 0.1279, 検証Acc: 0.9650\n",
      "\n",
      "エポック 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:15<00:00, 10.18it/s, loss=0.0236]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0236, 検証Loss: 0.1028, 検証Acc: 0.9690\n",
      "\n",
      "エポック 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:14<00:00, 10.23it/s, loss=0.0166]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0166, 検証Loss: 0.0961, 検証Acc: 0.9734\n",
      "ベストモデルを保存! Acc: 0.9734\n",
      "\n",
      "エポック 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:14<00:00, 10.24it/s, loss=0.0149]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0149, 検証Loss: 0.0783, 検証Acc: 0.9768\n",
      "ベストモデルを保存! Acc: 0.9768\n",
      "\n",
      "エポック 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:14<00:00, 10.31it/s, loss=0.00958]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 15.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0096, 検証Loss: 0.0766, 検証Acc: 0.9797\n",
      "ベストモデルを保存! Acc: 0.9797\n",
      "\n",
      "エポック 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:14<00:00, 10.34it/s, loss=0.00991]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0099, 検証Loss: 0.0762, 検証Acc: 0.9789\n",
      "\n",
      "エポック 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:14<00:00, 10.23it/s, loss=0.00897]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 15.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0090, 検証Loss: 0.0770, 検証Acc: 0.9793\n",
      "\n",
      "エポック 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:14<00:00, 10.24it/s, loss=0.00631]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 14.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0063, 検証Loss: 0.0751, 検証Acc: 0.9802\n",
      "ベストモデルを保存! Acc: 0.9802\n",
      "\n",
      "エポック 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:14<00:00, 10.27it/s, loss=0.00499]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0050, 検証Loss: 0.0737, 検証Acc: 0.9812\n",
      "ベストモデルを保存! Acc: 0.9812\n",
      "\n",
      "エポック 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:15<00:00, 10.19it/s, loss=0.00379]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 14.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0038, 検証Loss: 0.0727, 検証Acc: 0.9816\n",
      "ベストモデルを保存! Acc: 0.9816\n",
      "\n",
      "エポック 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:15<00:00, 10.18it/s, loss=0.00384]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 15.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0038, 検証Loss: 0.0733, 検証Acc: 0.9819\n",
      "ベストモデルを保存! Acc: 0.9819\n",
      "\n",
      "エポック 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:14<00:00, 10.31it/s, loss=0.00435]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 14.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0044, 検証Loss: 0.0741, 検証Acc: 0.9816\n",
      "\n",
      "エポック 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習: 100%|██████████| 153/153 [00:14<00:00, 10.23it/s, loss=0.00342]\n",
      "検証: 100%|██████████| 42/42 [00:02<00:00, 14.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習Loss: 0.0034, 検証Loss: 0.0751, 検証Acc: 0.9823\n",
      "ベストモデルを保存! Acc: 0.9823\n",
      "\n",
      "学習完了。ベスト精度: 0.9823\n"
     ]
    }
   ],
   "source": [
    "train_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"submission用推論スクリプト\"\"\"\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(\n",
    "    model: torch.nn.Module,\n",
    "    loader: torch.utils.data.DataLoader,\n",
    "    device: str,\n",
    ") -> list[int]:\n",
    "    \"\"\"予測を生成\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"予測\"):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = outputs.max(1)\n",
    "        predictions.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def inference_main():\n",
    "    cfg = Config()\n",
    "\n",
    "    # テストデータ読み込み\n",
    "    test_side = pd.read_csv(cfg.data_dir / \"test_meta.csv\")\n",
    "    test_top = pd.read_csv(cfg.data_dir / \"test_top_meta.csv\")\n",
    "\n",
    "    print(f\"テストsideサンプル数: {len(test_side)}\")\n",
    "    print(f\"テストtopサンプル数: {len(test_top)}\")\n",
    "\n",
    "    # モデル作成と重み読み込み\n",
    "    model = create_model(cfg.model_name, cfg.num_classes, pretrained=False)\n",
    "    model_path = cfg.output_dir / \"best_model.pth\"\n",
    "\n",
    "    if not model_path.exists():\n",
    "        print(f\"モデルが見つかりません: {model_path}\")\n",
    "        print(\"先にtrain.pyを実行してください!\")\n",
    "        return\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path, map_location=cfg.device, weights_only=True))\n",
    "    model = model.to(cfg.device)\n",
    "    print(f\"モデルを読み込みました: {model_path}\")\n",
    "\n",
    "    # データローダー作成\n",
    "    test_side_loader = create_dataloader(\n",
    "        test_side, cfg.image_dir, cfg.img_size, cfg.batch_size, cfg.num_workers, is_train=False, is_test=True\n",
    "    )\n",
    "    test_top_loader = create_dataloader(\n",
    "        test_top, cfg.image_dir, cfg.img_size, cfg.batch_size, cfg.num_workers, is_train=False, is_test=True\n",
    "    )\n",
    "\n",
    "    # 予測\n",
    "    preds_side = predict(model, test_side_loader, cfg.device)\n",
    "    preds_top = predict(model, test_top_loader, cfg.device)\n",
    "\n",
    "    print(f\"side予測数: {len(preds_side)}\")\n",
    "    print(f\"top予測数: {len(preds_top)}\")\n",
    "\n",
    "    # submission作成（sample_submissionに従いsideのみ）\n",
    "    submission = pd.DataFrame({\"label_id\": preds_side})\n",
    "    submission_path = cfg.output_dir / \"submission.csv\"\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    print(f\"submissionを保存: {submission_path}\")\n",
    "\n",
    "    # 全予測も保存\n",
    "    full_submission = pd.DataFrame({\"label_id\": preds_side + preds_top})\n",
    "    full_submission.to_csv(cfg.output_dir / \"submission_full.csv\", index=False)\n",
    "\n",
    "    # 予測分布を表示\n",
    "    print(\"\\n予測分布 (side):\")\n",
    "    print(pd.Series(preds_side).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストsideサンプル数: 7500\n",
      "テストtopサンプル数: 1480\n",
      "モデルを読み込みました: /kaggle/output/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "予測: 100%|██████████| 59/59 [00:43<00:00,  1.35it/s]\n",
      "予測: 100%|██████████| 12/12 [00:10<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "side予測数: 7500\n",
      "top予測数: 1480\n",
      "submissionを保存: /kaggle/output/submission.csv\n",
      "\n",
      "予測分布 (side):\n",
      "0       38\n",
      "1      754\n",
      "2      759\n",
      "3      770\n",
      "4      766\n",
      "5      741\n",
      "6      735\n",
      "7      752\n",
      "8       48\n",
      "9     1277\n",
      "10     860\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "inference_main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atmacup-22-ca-x-atmacup-3rd (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
